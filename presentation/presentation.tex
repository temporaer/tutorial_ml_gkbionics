% rubber: module xelatex
\documentclass[english,final,compress]{beamer}
%\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\mode<beamer>{\usetheme{Bonn}}
\usepackage{fontspec}
\defaultfontfeatures{Mapping=tex-text}
\usepackage{xunicode}
\usepackage{xltxtra}
\setmainfont[Scale=0.86,Mapping=tex-text]{News Gothic MT}
\setsansfont[Scale=0.86,Mapping=tex-text]{News Gothic MT}
\setmonofont[Scale=0.86,Mapping=tex-text]{Andale Mono}
\usepackage{polyglossia}
\setdefaultlanguage{english}
\usepackage[EU1]{fontenc}
\usepackage{listings}
\usepackage{color}
\usepackage{csquotes}
\usepackage{mdwtab}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage{listings}
\renewcommand\maketitle{\frame[plain]{\titlepage}\addtocounter{framenumber}{-1}}
\providecommand{\alert}[1]{\textbf{#1}}

\setbeamercolor{insult}{fg=black,bg=red!30}
\setbeamercolor{noinsult}{fg=black,bg=green!30}
\setbeamerfont*{myserif}{family=\rmfamily,size=\scriptsize}

\title{Tutorial Machine Learning in Python}
\author{Andreas M\"{u}ller, Hannes Schulz, Nenad Bire\v sev and Sven 
    Behnke\\[5mm]\includegraphics[width=.2\linewidth]{style/Logo_UBo_h24_4c-crop}}
\date{GK Bionik Tutorial 2012}
\begin{document}

\maketitle


\lstset{%
    basicstyle=\small\tt,
    keywordstyle=\color{beamer@bonnblue}\bfseries, % style for keywords
    numbers=none, % where to put the line-numbers
    numberstyle=\tiny, % the size of the fonts that are used for the line-numbers
    showspaces=false, % show spaces adding particular underscores
    showstringspaces=false, % underline spaces within strings
    showtabs=false, % show tabs within strings adding particular underscores
    tabsize=2, % sets default tabsize to 2 spaces
    captionpos=b, % sets the caption-position to bottom
    breaklines=true, % sets automatic line breaking
    breakatwhitespace=false, 
}
\newcommand\fenc{f_{\mathrm{enc}}}
\newcommand\fdec{f_{\mathrm{dec}}}
\newcommand\Wand{\ensuremath{W_{\mathbf{and}}}}
\newcommand\Wor{\ensuremath{W_{\mathbf{or}}}}
\newcommand{\w}[1]{\ensuremath{\mathbf{#1}}}
\newcommand\loss{\ell}

\frame[plain]{\frametitle{Outline}\tableofcontents\addtocounter{framenumber}{-1}}
\section{Introduction to Python}

%\begin{frame}
%    \frametitle{Machine Learning Overview}
%    \begin{itemize}
%        \item Intro: Sven
%        \item Python: Hannes
%        \item Before Lunch: Unsupervised Learning (Hannes)
%        \item After Lunch: Supervised Learning (Nenad LinReg, Andy LogReg/kNN)
%    \end{itemize}
%\end{frame}


\begin{frame}
    \frametitle{A Short Introduction to Python}
    \begin{itemize}
        \item Please log in, using:
            \begin{description}
                \item[Username] \alert{gkbionik}
                \item[Password] \alert{tut0rial} (with a zero instead of the 
                    ``o''!)
            \end{description}
    \end{itemize}
\end{frame}


\section{Unsupervised Learning}

\subsection{PCA}

\input{pca.tex}

\subsection{k-Means}

\input{kmeans.tex}

\section{Supervised Learning}


\begin{frame}
    \frametitle{Supervised Learning -- General}
    \begin{itemize}
	\item Task: Learn the function $ y = f(x) $ which predicts the output $y$ for the given input $x$, knowing the desired output
        \item Each example in data is a tuple of the input and desired output (target)
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Example: Supervised Learning}
    \begin{itemize}
       \item Input Data: 40 examples of persons (age, height, smoker). 
	\item Targets: Weight of the person (desired output)
	\item Goal: Learn a function which predicts the weight for the new person
		knowing the age, height, nationality of person.

    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Training / Test data}
    \begin{itemize}
	\item Learning is done on the training data, for which we know the input and targets
	\item To test if the model learned to predict the output, we use test data. 		
    \end{itemize}
\end{frame}

\subsection{Linear Regression}

\input{linreg.tex}

\subsection{Classification}
\begin{frame}
    \frametitle{Classification}
    \begin{itemize}
        \item Predict to which class a data point belongs.
        \item Training data are pairs $\left( (x_0, y_0), \cdots, (x_N, y_N)
                \right), x_i \in \mathbb{R}^n, y_i \in \{0, \cdots, k\}$
        \item Classical example: Spam / Ham.
        \item All classes known beforehand.
        \item Other examples: Digit recognition, cancer benign/malignant, \ldots
    \end{itemize}
\end{frame}

\subsection{Logistic Regression}

\input{logreg.tex}

\subsection{$k$ Nearest Neighbors}

\input{knn.tex}

\end{document}
